#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
OCRå¤„ç†å™¨æ¨¡å— - ä½¿ç”¨å¤§æ¨¡å‹OCRåŠŸèƒ½
"""

import os
import time
import logging
import cv2
import numpy as np
import io
from PIL import Image
import configparser
import requests

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class OCRProcessor:
    """
    OCRå¤„ç†å™¨ç±» - ä½¿ç”¨å¤§æ¨¡å‹OCRåŠŸèƒ½
    
    ç”¨äºå¤„ç†å›¾åƒOCRè¯†åˆ«ï¼Œä½¿ç”¨å¤§æ¨¡å‹çš„è§†è§‰OCRèƒ½åŠ›ã€‚
    """
    
    def __init__(self, config, logger=None):
        """
        åˆå§‹åŒ–OCRå¤„ç†å™¨
        
        å‚æ•°:
            config: é…ç½®å¯¹è±¡
            logger: æ—¥å¿—è®°å½•å™¨
        """
        # è®¾ç½®æ—¥å¿—è®°å½•å™¨
        self.logger = logger or logging.getLogger(__name__)
        
        # ä»é…ç½®ä¸­è¯»å–OCRè®¾ç½®
        self.model_name = config.get('ocr', 'model_name', fallback='qwen-vl-max')
        self.timeout = config.getint('ocr', 'timeout', fallback=30)
        self.retry_count = config.getint('ocr', 'retry_count', fallback=3)
        self.batch_size = config.getint('ocr', 'batch_size', fallback=5)
        self.preprocess = config.getboolean('ocr', 'preprocess', fallback=False)
        
        # è¯»å–APIé…ç½®
        self.api_url = config.get('ocr', 'api_url')
        self.api_key = config.get('ocr', 'api_key')
        
        # éªŒè¯APIé…ç½®
        if not self.api_url or not self.api_key or self.api_key == "YOUR_API_KEY_HERE":
            self.logger.error("APIé…ç½®æ— æ•ˆï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„API URLå’Œå¯†é’¥")
            raise ValueError("APIé…ç½®æ— æ•ˆï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„API URLå’Œå¯†é’¥")
        
        # åˆå§‹åŒ–tokenè®¡æ•°å™¨
        self.total_tokens = 0
        
        # æ£€æŸ¥APIè¿é€šæ€§
        if not self._check_api_connectivity():
            raise Exception("OCR APIæ— æ³•è¿é€š")
        
        self.logger.info(f"ğŸ” åˆå§‹åŒ–OCRå¤„ç†å™¨: æ¨¡å‹={self.model_name}")
    
    def _check_api_connectivity(self):
        """
        æ£€æŸ¥OCR APIè¿é€šæ€§
        """
        try:
            # ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯éªŒè¯è¿é€šæ€§
            from openai import OpenAI
            import base64
            import numpy as np
            from PIL import Image
            
            # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾åƒ - ç™½åº•é»‘å­—"æµ‹è¯•"
            test_image = np.ones((100, 200, 3), dtype=np.uint8) * 255  # ç™½è‰²èƒŒæ™¯
            # æ·»åŠ ä¸€äº›é»‘è‰²æ–‡æœ¬ (ç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…ä¸Šåªæ˜¯ä¸€ä¸ªé»‘è‰²çŸ©å½¢)
            test_image[40:60, 50:150] = 0
            
            # å°†NumPyæ•°ç»„è½¬æ¢ä¸ºPILå›¾åƒ
            pil_image = Image.fromarray(test_image.astype('uint8'))
            
            # å°†PILå›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç 
            buffer = io.BytesIO()
            pil_image.save(buffer, format="JPEG")
            base64_image = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
            client = OpenAI(
                api_key=self.api_key,
                base_url=self.api_url,
            )
            
            # å‘é€åŒ…å«å›¾åƒçš„è¯·æ±‚
            self.logger.debug("å‘é€OCR APIè¿é€šæ€§æµ‹è¯•è¯·æ±‚")
            completion = client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": [{"type": "text", "text": "ä½ æ˜¯ä¸€ä¸ªOCRåŠ©æ‰‹ï¼Œè¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„æ–‡å­—ã€‚"}]},
                    {"role": "user", "content": [
                        {"type": "text", "text": "è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ–‡å­—"},
                        {"type": "image_url", "image_url": {
                            "url": f"data:image/jpeg;base64,{base64_image}"
                        }}
                    ]},
                ],
                max_tokens=10  # æœ€å°åŒ–è¯·æ±‚ä»¥èŠ‚çœèµ„æº
            )
            
            self.logger.debug(f"OCR APIè¿é€šæ€§æµ‹è¯•å“åº”: {completion}")
            # å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼Œåˆ™è¿æ¥æˆåŠŸ
            return True
        except ImportError:
            self.logger.warning("OpenAI åŒ…æœªå®‰è£…ï¼Œæ— æ³•éªŒè¯ API è¿é€šæ€§")
            return False
        except Exception as e:
            self.logger.warning(f"OCR APIè¿é€šæ€§æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def ocr_page(self, image):
        """
        OCRå¤„ç†å•é¡µå›¾åƒ
        
        å‚æ•°:
            image: å›¾åƒæ•°æ®ï¼ˆNumPyæ•°ç»„æˆ–å­—èŠ‚æµï¼‰
            
        è¿”å›:
            dict: OCRç»“æœï¼ŒåŒ…å«æ–‡æœ¬ã€ç½®ä¿¡åº¦ç­‰ä¿¡æ¯
        """
        # å›¾åƒé¢„å¤„ç†
        if self.preprocess:
            image = self._preprocess_image(image)
        
        # é‡è¯•æœºåˆ¶
        for attempt in range(self.retry_count):
            try:
                self.logger.debug(f"OCRå¤„ç†å°è¯• {attempt+1}/{self.retry_count}")
                
                # è°ƒç”¨å¤§æ¨¡å‹OCR
                result = self._call_llm_ocr(image)
                
                # è®°å½•æ–‡æœ¬é•¿åº¦
                text_length = len(result.get('text', ''))
                self.logger.debug(f"OCRå¤„ç†æˆåŠŸ: æ–‡æœ¬é•¿åº¦={text_length}")
                
                # æ›´æ–°tokenä½¿ç”¨æƒ…å†µ
                if 'token_usage' in result:
                    token_usage = result['token_usage']
                    self.total_tokens += token_usage
                    if self.logger:
                        self.logger.debug(f"ğŸ”¢ ç´¯è®¡tokenä½¿ç”¨é‡: {self.total_tokens}")
                
                return result
                
            except Exception as e:
                self.logger.warning(f"OCRå¤„ç†å¤±è´¥: {e}")
                
                if attempt < self.retry_count - 1:
                    # æŒ‡æ•°é€€é¿
                    wait_time = 2 ** attempt
                    self.logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"OCRå¤„ç†å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {e}")
                    raise
    
    def batch_process(self, images):
        """
        æ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒ
        
        å‚æ•°:
            images: å›¾åƒåˆ—è¡¨
            
        è¿”å›:
            list: OCRç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, image in enumerate(images):
            self.logger.info(f"å¤„ç†å›¾åƒ {i+1}/{len(images)}")
            result = self.ocr_page(image)
            results.append(result)
        
        return results
    
    def _preprocess_image(self, image):
        """
        å›¾åƒé¢„å¤„ç†
        
        å‚æ•°:
            image: åŸå§‹å›¾åƒ
            
        è¿”å›:
            å¤„ç†åçš„å›¾åƒ
        """
        self.logger.debug("æ‰§è¡Œå›¾åƒé¢„å¤„ç†")
        
        # ç¡®ä¿å›¾åƒæ˜¯NumPyæ•°ç»„
        if isinstance(image, bytes):
            nparr = np.frombuffer(image, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        # è½¬æ¢ä¸ºç°åº¦å›¾
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # é«˜æ–¯æ¨¡ç³Šå»å™ª
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        # è‡ªé€‚åº”äºŒå€¼åŒ–
        _, binary = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
        
        return binary
    
    def _call_llm_ocr(self, image):
        """
        è°ƒç”¨å¤§æ¨¡å‹OCRåŠŸèƒ½
        
        å‚æ•°:
            image: å›¾åƒæ•°æ®
            
        è¿”å›:
            dict: OCRç»“æœ
        """
        self.logger.debug(f"ä½¿ç”¨OpenAIå…¼å®¹æ¥å£è°ƒç”¨é˜¿é‡Œäº‘OCRæœåŠ¡")
        
        try:
            from openai import OpenAI
            import base64
            from io import BytesIO
            from PIL import Image as PILImage
            import tempfile
            import os
            import json
            
            # ç¡®ä¿å›¾åƒæ˜¯æ­£ç¡®çš„æ ¼å¼
            if isinstance(image, np.ndarray):
                # å°†NumPyæ•°ç»„è½¬æ¢ä¸ºPILå›¾åƒ
                if len(image.shape) == 2:  # ç°åº¦å›¾åƒ
                    pil_image = PILImage.fromarray(image)
                    self.logger.debug(f"è½¬æ¢ç°åº¦å›¾åƒä¸ºPILå›¾åƒ")
                else:  # å½©è‰²å›¾åƒ
                    # ç¡®ä¿å›¾åƒæ˜¯BGRæ ¼å¼ï¼ˆOpenCVé»˜è®¤ï¼‰å¹¶è½¬æ¢ä¸ºRGBï¼ˆPILéœ€è¦ï¼‰
                    if image.shape[2] == 3:  # å½©è‰²å›¾åƒ
                        pil_image = PILImage.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
                        self.logger.debug(f"è½¬æ¢BGRå½©è‰²å›¾åƒä¸ºPILå›¾åƒ")
                    else:  # å¯èƒ½æ˜¯BGRA
                        pil_image = PILImage.fromarray(cv2.cvtColor(image, cv2.COLOR_BGRA2RGBA))
                        self.logger.debug(f"è½¬æ¢BGRAå½©è‰²å›¾åƒä¸ºPILå›¾åƒ")
            elif isinstance(image, bytes):
                # å·²ç»æ˜¯å­—èŠ‚æµï¼Œè½¬æ¢ä¸ºPILå›¾åƒ
                try:
                    pil_image = PILImage.open(BytesIO(image))
                    self.logger.debug(f"ä»å­—èŠ‚æµè½¬æ¢ä¸ºPILå›¾åƒ")
                except Exception as e:
                    self.logger.error(f"æ— æ³•è§£æå›¾åƒå­—èŠ‚æµ: {e}")
                    raise ValueError(f"æ— æ•ˆçš„å›¾åƒå­—èŠ‚æµ: {e}")
            else:
                self.logger.error(f"ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {type(image)}")
                raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: {type(image)}")
            
            # å°†å›¾åƒä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as temp_file:
                temp_image_path = temp_file.name
                pil_image.save(temp_image_path, format="PNG")
                self.logger.debug(f"å›¾åƒå·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶")
            
            try:
                # å°†å›¾åƒè½¬æ¢ä¸ºbase64ç¼–ç 
                def encode_image(image_path):
                    with open(image_path, "rb") as image_file:
                        return base64.b64encode(image_file.read()).decode("utf-8")
                
                # è·å–å›¾åƒçš„base64ç¼–ç 
                base64_image = encode_image(temp_image_path)
                self.logger.debug(f"å›¾åƒå·²è½¬æ¢ä¸ºbase64ç¼–ç ")
                
                # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
                client = OpenAI(
                    api_key=self.api_key,
                    base_url=self.api_url,
                )
                
                # æ„å»ºæ¶ˆæ¯
                messages = [
                    {
                        "role": "system",
                        "content": [{"type": "text", "text": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„OCRåŠ©æ‰‹ï¼Œè¯·è¯†åˆ«å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼ã€‚"}]
                    },
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/png;base64,{base64_image}"}
                            },
                            {"type": "text", "text": "è¯·è¯†åˆ«è¿™å¼ å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—å†…å®¹ï¼Œä¿æŒåŸæœ‰æ ¼å¼ã€‚"}
                        ]
                    }
                ]
                
                # å‘é€è¯·æ±‚
                self.logger.debug(f"å¼€å§‹å‘é€OCRè¯·æ±‚")
                completion = client.chat.completions.create(
                    model=self.model_name,
                    messages=messages,
                    timeout=self.timeout
                )
                self.logger.debug(f"è¯·æ±‚å·²å®Œæˆï¼Œè·å–åˆ°å“åº”")
                
                # æå–æ–‡æœ¬å†…å®¹
                text_content = completion.choices[0].message.content
                
                # æå–tokenä½¿ç”¨æƒ…å†µ
                token_usage = 0
                if hasattr(completion, 'usage') and completion.usage:
                    token_usage = completion.usage.total_tokens
                    self.logger.debug(f"æœ¬æ¬¡è¯·æ±‚ä½¿ç”¨äº† {token_usage} tokens")
                
                # æ„å»ºç»“æœ
                result = {
                    "text": text_content.strip(),
                    "confidence": 0.9,  # å¤§æ¨¡å‹æ²¡æœ‰è¿”å›ç½®ä¿¡åº¦ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    "blocks": [],  # å¤§æ¨¡å‹æ²¡æœ‰è¿”å›å—ä¿¡æ¯
                    "language": {
                        "code": "zh-CN",
                        "name": "ç®€ä½“ä¸­æ–‡"
                    },
                    "token_usage": token_usage
                }
                
                return result
            except Exception as e:
                self.logger.error(f"è°ƒç”¨OCR APIè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                # å°è¯•æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                if hasattr(e, 'response') and hasattr(e.response, 'text'):
                    self.logger.error(f"APIå“åº”å†…å®¹: {e.response.text}")
                raise e
            finally:
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_image_path):
                    os.remove(temp_image_path)
                    self.logger.debug(f"å·²åˆ é™¤ä¸´æ—¶æ–‡ä»¶")
            
        except ImportError as e:
            self.logger.error(f"å¯¼å…¥å¿…è¦çš„åŒ…å¤±è´¥: {e}")
            raise Exception(f"å¯¼å…¥å¿…è¦çš„åŒ…å¤±è´¥: {e}")
        except Exception as e:
            self.logger.error(f"è°ƒç”¨OCR APIå¤±è´¥: {e}")
            raise Exception(f"è°ƒç”¨OCR APIå¤±è´¥: {e}")
    
    def detect_primary_language(self, ocr_result):
        """
        æ£€æµ‹ä¸»è¦è¯­è¨€
        
        å‚æ•°:
            ocr_result: OCRç»“æœ
            
        è¿”å›:
            str: è¯­è¨€ä»£ç 
        """
        if "language" not in ocr_result:
            return "unknown"
        
        # æ‰¾å‡ºç½®ä¿¡åº¦æœ€é«˜çš„è¯­è¨€
        languages = ocr_result["language"]
        if not languages:
            return "unknown"
        
        return max(languages.items(), key=lambda x: x[1])[0]
